import pandas as pd
import numpy as np
import requests
import io
import json
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from dinov2_numpy import Dinov2Numpy
from preprocess_image import resize_short_side
from PIL import Image

# ================= é…ç½®åŒº =================
LIMIT = 10000  # ä»»åŠ¡äºŒæœ€ä½æ ‡å‡†
MAX_WORKERS = 20  # å¹¶è¡Œä¸‹è½½çº¿ç¨‹æ•°
DATA_PATH = "data.csv"  # åŸå§‹æ•°æ®
WEIGHTS_PATH = "vit-dinov2-base.npz"


# ==========================================

def process_row(row, model):
    """å•æ¡æ•°æ®å¤„ç†é€»è¾‘"""
    url = row['image_url']
    caption = row['caption']
    try:
        # 1. ä¸‹è½½å›¾ç‰‡
        resp = requests.get(url, timeout=5, stream=True)
        if resp.status_code != 200:
            return None

        # 2. é¢„å¤„ç†
        img = Image.open(io.BytesIO(resp.content)).convert("RGB")
        img_tensor = resize_short_side(img)  # è°ƒç”¨ä½ å†™çš„ 224 + 14å€æ•°å¯¹é½å‡½æ•°

        # 3. æå–ç‰¹å¾
        feat = model(img_tensor)[0]

        # 4. å½’ä¸€åŒ– (æ–¹ä¾¿åç»­ç›´æ¥ç”¨ç‚¹ç§¯ç®—ç›¸ä¼¼åº¦)
        norm_feat = feat / (np.linalg.norm(feat) + 1e-6)

        return {
            "feature": norm_feat,
            "metadata": {"url": url, "caption": caption}
        }
    except Exception:
        # å¿½ç•¥ä¸‹è½½å¤±è´¥æˆ–æ ¼å¼é”™è¯¯çš„å›¾ç‰‡
        return None


def main():
    # 0. ç¯å¢ƒæ£€æŸ¥
    if not os.path.exists(WEIGHTS_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ {WEIGHTS_PATH}")
        return

    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– DINOv2 æ¨¡å‹...")
    weights = np.load(WEIGHTS_PATH)
    model = Dinov2Numpy(weights)

    print(f"ğŸ“– æ­£åœ¨è¯»å–æ•°æ®å¹¶å‡†å¤‡å¤„ç†å‰ {LIMIT} æ¡...")
    df = pd.read_csv(DATA_PATH).head(LIMIT)

    all_features = []
    all_metadata = []
    count = 0
    success_count = 0

    print(f"âš¡ å¼€å§‹å¹¶è¡Œæ„å»ºç´¢å¼• (çº¿ç¨‹æ•°: {MAX_WORKERS})...")

    # ä½¿ç”¨ ThreadPoolExecutor å¹¶å®æ—¶æ‰“å°è¿›åº¦
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {executor.submit(process_row, row, model): row for _, row in df.iterrows()}

        for future in as_completed(futures):
            count += 1
            result = future.result()

            if result:
                all_features.append(result["feature"])
                all_metadata.append(result["metadata"])
                success_count += 1

            if count % 100 == 0:
                print(f"â³ è¿›åº¦: {count}/{LIMIT} | æˆåŠŸæå–: {success_count}")

    # ================= ä¿å­˜é€»è¾‘ (æ ¸å¿ƒä¿®æ”¹) =================
    print("\nğŸ’¾ æ­£åœ¨å°†ç´¢å¼•å†™å…¥ç£ç›˜...")

    if len(all_features) > 0:
        # è·å–å½“å‰ç»å¯¹è·¯å¾„ï¼Œé˜²æ­¢æ–‡ä»¶â€œå¤±è¸ªâ€
        current_dir = os.path.dirname(os.path.abspath(__file__))
        feat_path = os.path.join(current_dir, "gallery_features.npy")
        meta_path = os.path.join(current_dir, "metadata.json")

        # æ‰§è¡Œä¿å­˜
        np.save(feat_path, np.array(all_features))
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(all_metadata, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ„å»ºå®Œæˆï¼")
        print(f"ğŸ“¦ æœ€ç»ˆæœ‰æ•ˆç´¢å¼•æ•°é‡: {success_count}")
        print(f"ğŸ“ ç‰¹å¾åº“è·¯å¾„: {feat_path}")
        print(f"ğŸ“ å…ƒæ•°æ®è·¯å¾„: {meta_path}")
    else:
        print("âŒ ä¸¥é‡é”™è¯¯: æ²¡æœ‰æˆåŠŸæå–åˆ°ä»»ä½•ç‰¹å¾ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– data.csv ä¸­çš„å›¾ç‰‡é“¾æ¥ã€‚")


if __name__ == "__main__":
    main()